https://www.kaggle.com/code/bennyfung/model-interpretability-xgboost-shap



 Package and Library
import warnings
from numba import NumbaDeprecationWarning
warnings.filterwarnings("ignore", category=NumbaDeprecationWarning)

# Data Standardization and Encoding
from sklearn.preprocessing import RobustScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# Modelling
from sklearn import model_selection, metrics
from sklearn.model_selection import train_test_split 

# Visualization Library, matplotlib and seaborn
%matplotlib inline
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.ticker import FuncFormatter

# Hide convergence warning for now
import warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

# Oversampling technique
from imblearn.over_sampling import SMOTE

# Random Forest
from sklearn.linear_model import LogisticRegression

import xgboost as xgb

# Random Search for Hyperparameter Turning
from sklearn.model_selection import RandomizedSearchCV

# Additional packages
from pandas.api.types import is_numeric_dtype
from scipy.stats import randint as sp_randint


# Model Explanation
import shap
from sklearn.inspection import permutation_importance



import random


 Load the Data
# Read the data
df_heart = pd.read_csv('../input/heart-failure-clinical-data/heart_failure_clinical_records_dataset.csv')
print('No. of row: {}, no. of columns: {}'.format(df_heart.shape[0], df_heart.shape[1]))
No. of row: 299, no. of columns: 13





# Basic information about the dataset
df_heart.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 299 entries, 0 to 298
Data columns (total 13 columns):
 #   Column                    Non-Null Count  Dtype  
---  ------                    --------------  -----  
 0   age                       299 non-null    float64
 1   anaemia                   299 non-null    int64  
 2   creatinine_phosphokinase  299 non-null    int64  
 3   diabetes                  299 non-null    int64  
 4   ejection_fraction         299 non-null    int64  
 5   high_blood_pressure       299 non-null    int64  
 6   platelets                 299 non-null    float64
 7   serum_creatinine          299 non-null    float64
 8   serum_sodium              299 non-null    int64  
 9   sex                       299 non-null    int64  
 10  smoking                   299 non-null    int64  
 11  time                      299 non-null    int64  
 12  DEATH_EVENT               299 non-null    int64  
dtypes: float64(3), int64(10)
memory usage: 30.5 KB

3.1. Distribution of Target Label
# check whether the data set is balanced

def auto_fmt (pct_value):
    return '{:.0f}\n({:.2f}%)'.format(df_heart['DEATH_EVENT'].value_counts().sum()*pct_value/100,pct_value) 

df_death_count = df_heart['DEATH_EVENT'].value_counts().rename_axis('Death Event').reset_index(name='Case Count')

fig = plt.gcf()
fig.set_size_inches(6,6)
plt.pie(x=df_death_count['Case Count'], labels=df_death_count['Death Event'], autopct=auto_fmt, textprops={'fontsize': 16})
plt.title('Distribution of Target Label (i.e. Death Event)',  fontsize = 16)
Text(0.5, 1.0, 'Distribution of Target Label (i.e. Death Event)')

Observation: the distribution of target feature between death and non-death classes is not in equal proportion. However, the objective of this notebook is for model explainability, and thus no oversampling will be performed for simplicity.

3.2. Missing Value Handling / Replacement
df_null_value = df_heart.isnull().sum().rename_axis('Feature').reset_index(name='No of Null Value')

# Check if there are features with null value
df_null_value[df_null_value['No of Null Value']>0]
Feature	No of Null Value
Observation: there is no missing value in the data set.

3.3. Correlation Analysis
# Correlation matrix
corr_matrix = df_heart.corr()

fig, ax = plt.subplots(figsize=(10,10)) 
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

Observation: in general, the Heatmap shows low correlation among features, although the features of Smoking and Sex has correlation of 0.45, which shows a medium level of correlation.

3.4. Histogram and Boxplot for Numerical Features
# Histogram of numerical features
numerical_features = ['age', 'creatinine_phosphokinase', 'ejection_fraction', 'platelets',
                      'serum_creatinine', 'serum_sodium', 'time']

# Histgram for numercial features
fig, ax = plt.subplots(4, 2, figsize=(16,20))

for i in range(0, len(numerical_features)):
    sns.histplot(data=df_heart, x=df_heart[numerical_features[i]], bins=25, ax=ax[int(i/2),i % 2])    

plt.show()

# Box plot of numerical features
fig, ax = plt.subplots(4, 2, figsize=(16,20))

for i in range(0, len(numerical_features)):
    sns.boxplot(x="DEATH_EVENT",y=numerical_features[i],data=df_heart, ax=ax[int(i/2),i % 2])

plt.show()

Observation: there are outliers for numerical features of creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine and serum_sodium. We will handle outliers with IRQ Method.

3.5. Outlier Handling
for col in numerical_features:
    p75 = df_heart[df_heart[col] > 0][col].quantile(0.75)
    p25 = df_heart[df_heart[col] > 0][col].quantile(0.25)
    iqr = p75 - p25
    upper_limit = p75 + (1.5 * iqr)
    print('===={} with Upper Limit {:6.1f}, P75 {:6.1f}, P25 {:6.1f}, {} Outlier Records ========'.format(col, upper_limit, p75, p25, df_heart[df_heart[col] > upper_limit]['DEATH_EVENT'].count()))
    df_heart[col] = np.where (df_heart[col] > upper_limit, upper_limit, df_heart[col])
====age with Upper Limit   98.5, P75   70.0, P25   51.0, 0 Outlier Records ========
====creatinine_phosphokinase with Upper Limit 1280.2, P75  582.0, P25  116.5, 29 Outlier Records ========
====ejection_fraction with Upper Limit   67.5, P75   45.0, P25   30.0, 2 Outlier Records ========
====platelets with Upper Limit 440000.0, P75 303500.0, P25 212500.0, 14 Outlier Records ========
====serum_creatinine with Upper Limit    2.1, P75    1.4, P25    0.9, 29 Outlier Records ========
====serum_sodium with Upper Limit  149.0, P75  140.0, P25  134.0, 0 Outlier Records ========
====time with Upper Limit  398.0, P75  203.0, P25   73.0, 0 Outlier Records ========
# Re-print the Boxplot to check for outliers
fig, ax = plt.subplots(4, 2, figsize=(16,20))

for i in range(0, len(numerical_features)):
    sns.boxplot(x="DEATH_EVENT",y=numerical_features[i],data=df_heart, ax=ax[int(i/2),i % 2])

plt.show()

Observation: the IRQ is used to remove outliers. After the replacement of missing values and handling of abnormal values, the boxplots look more rational.

3.6. Count Plot for Categorical Features
fig, axs = plt.subplots(3, 2, figsize=(16,12))


# Count plot of categorical features
categorical_features = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking']
for feature, ax in zip(categorical_features, axs.flatten()):
    rel = sns.countplot(x=feature, data=df_heart, hue='DEATH_EVENT', ax=ax)
    rel.legend(['Normal', 'Death'])

Observation: from the count plots, it appears that there is an interdependence between a categorical variable and a target label.
4. Modelling
# Split the data into train and test data
y = df_heart['DEATH_EVENT']
X = df_heart.drop(['DEATH_EVENT'], axis = 1)

# Splitting data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print('No. of rows in X: {}, X_train: {}, and X_test: {}'.format(df_heart.shape[0], X_train.shape[0], X_test.shape[0]))
No. of rows in X: 299, X_train: 239, and X_test: 60

4.1. XGBoost
# XGBoost
model = xgb.XGBClassifier()
model.fit(X_train, y_train)

XGBClassifier
XGBClassifier(base_score=None, booster=None, callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              n_estimators=100, n_jobs=None, num_parallel_tree=None,
              predictor=None, random_state=None, ...)
# Prediction and accuracy score
y_pred = model.predict(X_test)
y_pred_prob = model.predict_proba(X_test)
print(metrics.classification_report(y_test, y_pred))
              precision    recall  f1-score   support

           0       0.74      0.89      0.81        35
           1       0.78      0.56      0.65        25

    accuracy                           0.75        60
   macro avg       0.76      0.72      0.73        60
weighted avg       0.75      0.75      0.74        60

5. Shapley Additive Explanations (Shap)
SHAP (SHapley Additive exPlanations) is a framework for model interpretability that calculates the impact of each feature on a prediction using Shapley values from cooperative game theory. It provides consistent and accurate explanations for individual predictions, allowing users to understand the importance of different features and detect potential biases in their machine learning models. By using SHAP, users can gain insights into their model's behavior in a flexible and efficient manner, fostering trust and understanding in machine learning applications.

5.1. Global Importance
Global Importance refers to understanding the overall impact and importance of features in the model across the entire dataset. It helps to identify the features that have the most significant influence on predictions in a general sense.

The Global Importance of SHAP enable us to identify the most influential features in your model, understand their effects on predictions, and assess their relative importance in a global context.
# Initialize the SHAP explainer
explainer = shap.Explainer(model, X)

# Calculate SHAP values for all instances
shap_values = explainer(X)

# Visualize global feature importance using summary plot
shap.summary_plot(shap_values, X)
No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored

Observation: Three important indication can be obtaned by analyzing the above SHAP chart. First, the features at the top have the most significant impact on predictions, while those at the bottom have less influence. Next, the position of each feature bar indicates the range of its impact on predictions. Lastly, each dot represents a data point, and the density around a region represents the contration of feature values.

Let's use the above results as examples, and the following findings can be derived. * Feature Importance: Among the features analyzed, Time emerges as the most important feature, indicating that it has the most significant impact on predictions. Serum_creatinine follows as the second most important feature, while high_blood_pressure appears to have the least influence on predictions. * Feature Effects: Features such as Time, Serum_creatinine, Ejection_fraction, Platelets, and Age exhibit a long tail to the right in the summary plot. This indicates that higher feature values for these variables have a greater impact on prediction. On the other hand, Time and Creatinine_phosphokinase show a tail to the left, suggesting that higher values of these features negatively impact the predictions. It is noted that Time has both postive and negative impact on prediction. * Feature Value Density: Certain features, such as Time, Serum_creatinine, Ejection_fraction, and Diabetes, demonstrate a high density of data points within specific ranges of feature values. This suggests that there is a concentration of data points with feature values falling within those particular ranges. Overall, the summary plot in SHAP helps you understand the relative importance of features in your model, their effects on predictions, and potential interactions between features. It assists in gaining insights into the decision-making process of your model and identifying areas for further analysis or improvement.

5.2. Local Importance
Local Importance focuses on understanding the impact and contribution of features for individual predictions. It helps to explain why a specific prediction was made by highlighting the importance of different features for that particular instance.

The Local Importance of SHAP exhibits what features are crucial factors in prediction.
# The SHAP library provides TreeExplaier for all tree-based algorithms, like LGBM and XGBoost
explainer = shap.TreeExplainer(model)

# Output the shap values of individual instances in a array format
shap_values = explainer.shap_values(X)
ntree_limit is deprecated, use `iteration_range` or model slicing instead.
# Setup the dataframe for the Shap values
df_shap = pd.DataFrame(shap_values, columns=X_test.columns)
df_shap.head(5)
age	anaemia	creatinine_phosphokinase	diabetes	ejection_fraction	high_blood_pressure	platelets	serum_creatinine	serum_sodium	sex	smoking	time
0	0.534262	-0.168865	0.467512	0.252139	1.599229	0.032664	-0.263944	1.504279	0.403668	-0.203482	-0.121900	3.636619
1	-0.236997	-0.300835	0.690870	0.214756	0.088025	-0.035917	-0.617615	-0.394645	0.308536	-0.179288	-0.148530	5.725294
2	0.155314	-0.168865	0.584716	0.089834	1.837441	-0.024044	0.520079	0.061105	0.731821	-0.175042	0.193165	4.431267
3	-0.350308	0.327832	-0.110452	0.100080	1.551820	-0.107907	0.551999	1.427441	-1.045564	-0.120335	-0.106283	3.699545
4	0.189889	0.180957	0.979419	-0.255764	1.674004	-0.024044	-0.194666	1.053351	0.504417	0.369586	-0.145497	3.598220
# For illustration, use all samples for prediction
y_pred = model.predict(X)

df_pred = pd.DataFrame(y_pred, columns=['pred'])
df_pred.head(5)
pred
0	1
1	1
2	1
3	1
4	1
# Check the shape of pred and shap dataframes
print('Pred size : {}, Shap size : {}'.format(df_pred.shape, df_shap.shape))
Pred size : (299, 1), Shap size : (299, 12)
# merge the prediction and shap values
df_pred_shap = pd.concat([df_pred,df_shap], axis=1)

df_pred_shap.head(5)
pred	age	anaemia	creatinine_phosphokinase	diabetes	ejection_fraction	high_blood_pressure	platelets	serum_creatinine	serum_sodium	sex	smoking	time
0	1	0.534262	-0.168865	0.467512	0.252139	1.599229	0.032664	-0.263944	1.504279	0.403668	-0.203482	-0.121900	3.636619
1	1	-0.236997	-0.300835	0.690870	0.214756	0.088025	-0.035917	-0.617615	-0.394645	0.308536	-0.179288	-0.148530	5.725294
2	1	0.155314	-0.168865	0.584716	0.089834	1.837441	-0.024044	0.520079	0.061105	0.731821	-0.175042	0.193165	4.431267
3	1	-0.350308	0.327832	-0.110452	0.100080	1.551820	-0.107907	0.551999	1.427441	-1.045564	-0.120335	-0.106283	3.699545
4	1	0.189889	0.180957	0.979419	-0.255764	1.674004	-0.024044	-0.194666	1.053351	0.504417	0.369586	-0.145497	3.598220
# set the true and false prediction into two differnt dataframes
df_pred_shap_1 = df_pred_shap[df_pred_shap['pred'] == 1].reset_index()
df_pred_shap_0 = df_pred_shap[df_pred_shap['pred'] == 0].reset_index()

print('True : {}, False :{}'.format(df_pred_shap_1.shape, df_pred_shap_0.shape))
True : (89, 14), False :(210, 14)
# randomly select an index from a dataframe
def random_index_selection(dataframe):
    index_list = dataframe.index.tolist()
    random_index = random.choice(index_list)
    return random_index

5.2.1 Local Importance for Diagnosed Case
# randomly select 4 rows
idx = [None] * 4

for i in [0,1,2,3]:
    idx[i] = random_index_selection(df_pred_shap_1)

print(idx)
[49, 55, 23, 23]
# Manually select some instances with high variance for illustration purpose
idx =[67, 52, 79, 42]

# Select the row corresponding to instance 0
instances = df_pred_shap_1.drop(['pred','index'], axis=1)
# print(instance)

# Create a bar chart of the feature values
fig, ax = plt.subplots(2, 2, figsize=(15,10))

# Create a bar chart in the first subplot

ax[0, 0].bar(instances.iloc[idx[0],:].index.tolist(), instances.iloc[idx[0],:].values.tolist())
ax[0, 1].bar(instances.iloc[idx[1],:].index.tolist(), instances.iloc[idx[1],:].values.tolist())
ax[1, 0].bar(instances.iloc[idx[2],:].index.tolist(), instances.iloc[idx[2],:].values.tolist())
ax[1, 1].bar(instances.iloc[idx[3],:].index.tolist(), instances.iloc[idx[3],:].values.tolist())

# ax.bar(instance.index, instance.values, ax[0][0])

# # Set labels and title
# ax.set_xlabel('Feature')
# ax.set_ylabel('Value')

# Set title for the first subplot
ax[0, 0].set_title('SHAP Values of Instance ' + str(idx[0]))
ax[0, 1].set_title('SHAP Values of Instance ' + str(idx[1]))
ax[1, 0].set_title('SHAP Values of Instance ' + str(idx[2]))
ax[1, 1].set_title('SHAP Values of Instance ' + str(idx[3]))

# Rotate x-axis labels if needed
# Rotate x-axis labels if needed
ax[0, 0].tick_params(axis='x', rotation=90)
ax[0, 1].tick_params(axis='x', rotation=90)
ax[1, 0].tick_params(axis='x', rotation=90)
ax[1, 1].tick_params(axis='x', rotation=90)

# Show the plot
plt.show()

Observation: Based on the Global Importance of SHAP, Time, Serum_creatinine, and Ejection_fraction are identified as the top three features with the most significant impact on predictions. However, it is important to note that while the significance of these top features in the Global Importance holds true for most cases, there are variations observed in individual instances, as indicated by the Local Importance analysis.

For example, in instance 67, Time has a negative impact on the prediction, which deviates from the overall importance assigned to it in the Global Importance analysis. In instance 42, Time emerges as the sole predictor, while other features have minimal significance in determining the prediction outcome. Instances 52 and 79 also exhibit distinct distributions in the local importance assigned by SHAP, further emphasizing the variation in feature significance at the individual level.

In summary, Global Importance is essential for explaining which features are significant in terms of overall predictive power. However, when it comes to explaining the prediction outcome of individual instances, Local Importance assumes an even more crucial role in providing insights into the decision-making process.

5.2.2 Local Importance for Health Case
# randomly select 4 rows
idx = [None] * 4

for i in [0,1,2,3]:
    idx[i] = random_index_selection(df_pred_shap_0)

print(idx)
[175, 7, 180, 17]
# Manually select some instances with high variance for illustration purpose
idx =[6, 41, 133, 136]


# Select the row corresponding to instance 0
instances = df_pred_shap_0.drop(['pred','index'], axis=1)
# print(instance)

# Create a bar chart of the feature values
fig, ax = plt.subplots(2, 2, figsize=(15,10))

# Create a bar chart in the first subplot

ax[0, 0].bar(instances.iloc[idx[0],:].index.tolist(), instances.iloc[idx[0],:].values.tolist())
ax[0, 1].bar(instances.iloc[idx[1],:].index.tolist(), instances.iloc[idx[1],:].values.tolist())
ax[1, 0].bar(instances.iloc[idx[2],:].index.tolist(), instances.iloc[idx[2],:].values.tolist())
ax[1, 1].bar(instances.iloc[idx[3],:].index.tolist(), instances.iloc[idx[3],:].values.tolist())

# ax.bar(instance.index, instance.values, ax[0][0])

# # Set labels and title
# ax.set_xlabel('Feature')
# ax.set_ylabel('Value')

# Set title for the first subplot
ax[0, 0].set_title('SHAP Values of Instance ' + str(idx[0]))
ax[0, 1].set_title('SHAP Values of Instance ' + str(idx[1]))
ax[1, 0].set_title('SHAP Values of Instance ' + str(idx[2]))
ax[1, 1].set_title('SHAP Values of Instance ' + str(idx[3]))

# Rotate x-axis labels if needed
# Rotate x-axis labels if needed
ax[0, 0].tick_params(axis='x', rotation=90)
ax[0, 1].tick_params(axis='x', rotation=90)
ax[1, 0].tick_params(axis='x', rotation=90)
ax[1, 1].tick_params(axis='x', rotation=90)

# Show the plot
plt.show()

Observation: When comparing the Local Importance of diagnosed cases, instances 133 and 136 demonstrate typical alignment between Global and Local Importance. However, instance 6 presents an intriguing Local Importance pattern with a high positive SHAP value for the Time feature. Similarly, instance 41 showcases a contradictory observation with a high positive value for the Serum_creatinine feature.

In instances 133 and 136, the Local Importance analysis aligns with the Global Importance, indicating consistent feature significance in determining the predictions. However, instance 6 stands out with a notable Local Importance pattern, indicating that the Time feature has a significant positive impact on the prediction outcome for this particular case. Similarly, in instance 41, the high positive value of the Serum_creatinine feature contradicts the overall feature importance, suggesting a unique influence on the prediction for this instance.

These diverse observations highlight the value of examining Local Importance to gain insights into individual cases, where specific features may deviate from the overall trends established by Global Importance analysis.
Thanks for your time to read my notebook. If you like my work, please give me an "upvote" as appreciation. Happy Kaggling together.